{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b758e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a book \\nNo'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s =  'This is a book \\nNo'\n",
    "s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8af2b0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s', 'ss', '\\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 's==ss==\\n'\n",
    "s.split('==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c78a68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer, BertConfig\n",
    "\n",
    "config = BertConfig.from_pretrained('bert-base-chinese', output_hidden_states=True)\n",
    "bert = BertModel.from_pretrained('bert-base-chinese', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bbe37ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0])\n",
      "tensor([2, 7])\n",
      "tensor([0, 0, 1, 0, 0, 0, 0, 1, 0, 0])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cat() received an invalid combination of arguments - got (Tensor, int), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8452\\1034607747.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensored_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensored_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: cat() received an invalid combination of arguments - got (Tensor, int), but expected one of:\n * (tuple of Tensors tensors, int dim, *, Tensor out)\n * (tuple of Tensors tensors, name dim, *, Tensor out)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "tensored_targets = torch.zeros(10).long()\n",
    "tensored_targets[torch.LongTensor([2,7])] = 1\n",
    "print(tensored_targets)\n",
    "print(torch.LongTensor([2,7]))\n",
    "print(tensored_targets)\n",
    "torch.cat(tensored_targets, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e4869d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertModel, BertTokenizer, BertConfig\n",
    "from pathlib2 import Path\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
    "\n",
    "def collate_fn(batch):\n",
    "    batched_data = []\n",
    "    batched_targets = []\n",
    "    paths = []\n",
    "    \n",
    "    for text, targets, path in batch:\n",
    "        paths.append(path)\n",
    "        \n",
    "        tensor_targets = torch.LongTensor(targets)\n",
    "        batched_targets.append(tensor_targets)\n",
    "        \n",
    "        bert_input = tokenizer.batch_encode_plus(text, pad_to_max_length=True, return_tensors='pt')\n",
    "        batched_data.append(bert_input)\n",
    "        \n",
    "    return batched_data, batched_targets, paths\n",
    "        \n",
    "\n",
    "class DRCDdataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        super().__init__()\n",
    "        self.files = list(Path(data_path).glob('*.txt'))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        path = self.files[index]\n",
    "        \n",
    "        return self.read_DRCD_file(path)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def read_DRCD_file(self, path):\n",
    "        seperator = '=========='\n",
    "        with Path(path).open('r', encoding='utf-8') as f:\n",
    "            raw_text = f.read()\n",
    "        paragraphs = [p for p in raw_text.strip().split(seperator) if len(p)>2]\n",
    "        \n",
    "        targets = []\n",
    "        text = []\n",
    "        for paragraph in paragraphs:\n",
    "            sentences = [s for s in paragraph.split('\\n') if len(s.split()) > 0]\n",
    "            sentences_targets = [0 for s in sentences[:-1]]\n",
    "            sentences_targets.append(1)\n",
    "            targets.extend(sentences_targets)\n",
    "        \n",
    "        \n",
    "            for sentence in sentences:\n",
    "                text.append(sentence)\n",
    "        \n",
    "        return text, targets, path\n",
    "        \n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, hidden_dim, hidden_layer, batch_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.config = BertConfig.from_pretrained('bert-base-chinese', output_hidden_states=True)\n",
    "        self.bert = BertModel.from_pretrained('bert-base-chinese', config=self.config)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.hidden_layer = hidden_layer\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        \n",
    "        self.lstm = nn.LSTM(768, hidden_dim, hidden_layer, bidirectional=True)\n",
    "        self.linear = nn.Linear(hidden_dim * 2,2)\n",
    "        \n",
    "    def pad_document(self, d, max_document_length):\n",
    "        d_length = d.size()[0]\n",
    "        v = d.unsqueeze(0).unsqueeze(0)\n",
    "        padded = F.pad(v, (0,0,0, max_document_length - d_length ))  # (1, 1, max_length, 768)\n",
    "        shape = padded.size()\n",
    "        return padded.view(shape[2], 1, shape[3])  # (max_length, 1, 768)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        batched_cls_lhs = []\n",
    "        doc_len = []\n",
    "        for x in batch:\n",
    "            _, cls_lhs, _ = self.bert(x['input_ids'], x['attention_mask'], return_dict=False)\n",
    "            doc_len.append(cls_lhs.shape[0])\n",
    "            batched_cls_lhs.append(cls_lhs)\n",
    "        max_doc_len = max(doc_len)\n",
    "        padded_doc = [self.pad_document(d,max_doc_len) for d in batched_cls_lhs]\n",
    "        docs_tensor = torch.cat(padded_doc, 1)\n",
    "        \n",
    "        x, _ = self.lstm(docs_tensor)\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "\n",
    "train_dataset = DRCDdataset(data_path=r'C:\\Users\\vince_wang\\research\\evaluate\\8.24\\DRCD\\train')\n",
    "train_dl = DataLoader(train_dataset, batch_size=3, collate_fn=collate_fn, shuffle=True)\n",
    "val_dl = DataLoader(train_dataset, batch_size=5, collate_fn=collate_fn, shuffle=True)\n",
    "model = Model(300,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a114ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Testing:   0%|                                                                                   | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out :  tensor([[[ 0.0302,  0.0638],\n",
      "         [-0.1270,  0.0902]],\n",
      "\n",
      "        [[-0.0028,  0.0966],\n",
      "         [-0.0892,  0.0539]],\n",
      "\n",
      "        [[-0.0163,  0.1791],\n",
      "         [-0.0986,  0.0594]],\n",
      "\n",
      "        [[-0.0553,  0.1464],\n",
      "         [-0.0427,  0.1128]],\n",
      "\n",
      "        [[-0.0456,  0.1178],\n",
      "         [-0.0667,  0.1029]],\n",
      "\n",
      "        [[-0.0443,  0.1871],\n",
      "         [-0.1292,  0.1443]],\n",
      "\n",
      "        [[-0.0733,  0.1796],\n",
      "         [-0.1027,  0.1617]],\n",
      "\n",
      "        [[-0.0267,  0.1852],\n",
      "         [-0.1364,  0.1602]],\n",
      "\n",
      "        [[-0.0454,  0.2020],\n",
      "         [-0.0483,  0.1681]],\n",
      "\n",
      "        [[-0.0804,  0.2077],\n",
      "         [-0.1023,  0.1831]],\n",
      "\n",
      "        [[-0.1548,  0.1890],\n",
      "         [-0.1048,  0.1923]],\n",
      "\n",
      "        [[-0.1001,  0.1974],\n",
      "         [-0.0208,  0.2049]],\n",
      "\n",
      "        [[-0.0884,  0.1881],\n",
      "         [-0.0229,  0.1732]],\n",
      "\n",
      "        [[-0.1029,  0.1737],\n",
      "         [-0.0396,  0.1322]],\n",
      "\n",
      "        [[-0.0223,  0.1419],\n",
      "         [-0.0701,  0.0939]],\n",
      "\n",
      "        [[-0.0460,  0.2277],\n",
      "         [-0.0237,  0.0964]],\n",
      "\n",
      "        [[-0.0913,  0.2396],\n",
      "         [-0.0189,  0.0427]],\n",
      "\n",
      "        [[-0.1385,  0.2220],\n",
      "         [-0.0272,  0.0530]],\n",
      "\n",
      "        [[-0.0179,  0.2292],\n",
      "         [-0.0297,  0.0493]],\n",
      "\n",
      "        [[-0.0256,  0.2064],\n",
      "         [-0.0306,  0.0437]],\n",
      "\n",
      "        [[-0.0058,  0.2571],\n",
      "         [-0.0312,  0.0393]],\n",
      "\n",
      "        [[ 0.0308,  0.2125],\n",
      "         [-0.0318,  0.0366]],\n",
      "\n",
      "        [[-0.0090,  0.2017],\n",
      "         [-0.0324,  0.0351]],\n",
      "\n",
      "        [[-0.0829,  0.1293],\n",
      "         [-0.0330,  0.0343]],\n",
      "\n",
      "        [[-0.0774,  0.1035],\n",
      "         [-0.0334,  0.0340]],\n",
      "\n",
      "        [[-0.0300,  0.1756],\n",
      "         [-0.0337,  0.0339]],\n",
      "\n",
      "        [[ 0.0105,  0.2270],\n",
      "         [-0.0340,  0.0340]],\n",
      "\n",
      "        [[-0.0456,  0.2743],\n",
      "         [-0.0342,  0.0340]],\n",
      "\n",
      "        [[ 0.0009,  0.2821],\n",
      "         [-0.0343,  0.0341]],\n",
      "\n",
      "        [[-0.0004,  0.2298],\n",
      "         [-0.0344,  0.0341]],\n",
      "\n",
      "        [[-0.0367,  0.1908],\n",
      "         [-0.0344,  0.0342]],\n",
      "\n",
      "        [[ 0.0028,  0.2161],\n",
      "         [-0.0345,  0.0342]],\n",
      "\n",
      "        [[-0.0484,  0.2299],\n",
      "         [-0.0345,  0.0342]],\n",
      "\n",
      "        [[-0.1015,  0.1834],\n",
      "         [-0.0345,  0.0342]],\n",
      "\n",
      "        [[-0.1008,  0.2320],\n",
      "         [-0.0345,  0.0343]],\n",
      "\n",
      "        [[-0.0366,  0.2353],\n",
      "         [-0.0344,  0.0342]],\n",
      "\n",
      "        [[-0.0642,  0.1900],\n",
      "         [-0.0344,  0.0342]],\n",
      "\n",
      "        [[-0.0907,  0.2176],\n",
      "         [-0.0343,  0.0342]],\n",
      "\n",
      "        [[-0.0304,  0.1921],\n",
      "         [-0.0341,  0.0342]],\n",
      "\n",
      "        [[ 0.0027,  0.2462],\n",
      "         [-0.0338,  0.0342]],\n",
      "\n",
      "        [[-0.1234,  0.2142],\n",
      "         [-0.0333,  0.0342]],\n",
      "\n",
      "        [[-0.1743,  0.1824],\n",
      "         [-0.0325,  0.0342]],\n",
      "\n",
      "        [[-0.1279,  0.2255],\n",
      "         [-0.0313,  0.0342]],\n",
      "\n",
      "        [[-0.0629,  0.2179],\n",
      "         [-0.0296,  0.0342]],\n",
      "\n",
      "        [[-0.1287,  0.1940],\n",
      "         [-0.0272,  0.0341]],\n",
      "\n",
      "        [[-0.0655,  0.2145],\n",
      "         [-0.0242,  0.0337]]], grad_fn=<ViewBackward0>)\n",
      "out.data.cpu :  [[0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Testing: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:12<00:00, 12.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax : tensor([[[0.5392, 0.4934],\n",
      "         [0.4608, 0.5066]],\n",
      "\n",
      "        [[0.5216, 0.5107],\n",
      "         [0.4784, 0.4893]],\n",
      "\n",
      "        [[0.5206, 0.5299],\n",
      "         [0.4794, 0.4701]],\n",
      "\n",
      "        [[0.4968, 0.5084],\n",
      "         [0.5032, 0.4916]],\n",
      "\n",
      "        [[0.5053, 0.5037],\n",
      "         [0.4947, 0.4963]],\n",
      "\n",
      "        [[0.5212, 0.5107],\n",
      "         [0.4788, 0.4893]],\n",
      "\n",
      "        [[0.5074, 0.5045],\n",
      "         [0.4926, 0.4955]],\n",
      "\n",
      "        [[0.5274, 0.5063],\n",
      "         [0.4726, 0.4937]],\n",
      "\n",
      "        [[0.5007, 0.5085],\n",
      "         [0.4993, 0.4915]],\n",
      "\n",
      "        [[0.5055, 0.5062],\n",
      "         [0.4945, 0.4938]],\n",
      "\n",
      "        [[0.4875, 0.4992],\n",
      "         [0.5125, 0.5008]],\n",
      "\n",
      "        [[0.4802, 0.4981],\n",
      "         [0.5198, 0.5019]],\n",
      "\n",
      "        [[0.4836, 0.5037],\n",
      "         [0.5164, 0.4963]],\n",
      "\n",
      "        [[0.4842, 0.5104],\n",
      "         [0.5158, 0.4896]],\n",
      "\n",
      "        [[0.5119, 0.5120],\n",
      "         [0.4881, 0.4880]],\n",
      "\n",
      "        [[0.4944, 0.5328],\n",
      "         [0.5056, 0.4672]],\n",
      "\n",
      "        [[0.4819, 0.5491],\n",
      "         [0.5181, 0.4509]],\n",
      "\n",
      "        [[0.4722, 0.5422],\n",
      "         [0.5278, 0.4578]],\n",
      "\n",
      "        [[0.5030, 0.5449],\n",
      "         [0.4970, 0.4551]],\n",
      "\n",
      "        [[0.5013, 0.5406],\n",
      "         [0.4987, 0.4594]],\n",
      "\n",
      "        [[0.5064, 0.5542],\n",
      "         [0.4936, 0.4458]],\n",
      "\n",
      "        [[0.5156, 0.5438],\n",
      "         [0.4844, 0.4562]],\n",
      "\n",
      "        [[0.5059, 0.5416],\n",
      "         [0.4941, 0.4584]],\n",
      "\n",
      "        [[0.4875, 0.5237],\n",
      "         [0.5125, 0.4763]],\n",
      "\n",
      "        [[0.4890, 0.5174],\n",
      "         [0.5110, 0.4826]],\n",
      "\n",
      "        [[0.5009, 0.5354],\n",
      "         [0.4991, 0.4646]],\n",
      "\n",
      "        [[0.5111, 0.5481],\n",
      "         [0.4889, 0.4519]],\n",
      "\n",
      "        [[0.4971, 0.5598],\n",
      "         [0.5029, 0.4402]],\n",
      "\n",
      "        [[0.5088, 0.5617],\n",
      "         [0.4912, 0.4383]],\n",
      "\n",
      "        [[0.5085, 0.5488],\n",
      "         [0.4915, 0.4512]],\n",
      "\n",
      "        [[0.4994, 0.5391],\n",
      "         [0.5006, 0.4609]],\n",
      "\n",
      "        [[0.5093, 0.5453],\n",
      "         [0.4907, 0.4547]],\n",
      "\n",
      "        [[0.4965, 0.5488],\n",
      "         [0.5035, 0.4512]],\n",
      "\n",
      "        [[0.4832, 0.5372],\n",
      "         [0.5168, 0.4628]],\n",
      "\n",
      "        [[0.4834, 0.5493],\n",
      "         [0.5166, 0.4507]],\n",
      "\n",
      "        [[0.4995, 0.5501],\n",
      "         [0.5005, 0.4499]],\n",
      "\n",
      "        [[0.4925, 0.5389],\n",
      "         [0.5075, 0.4611]],\n",
      "\n",
      "        [[0.4859, 0.5457],\n",
      "         [0.5141, 0.4543]],\n",
      "\n",
      "        [[0.5009, 0.5394],\n",
      "         [0.4991, 0.4606]],\n",
      "\n",
      "        [[0.5091, 0.5528],\n",
      "         [0.4909, 0.4472]],\n",
      "\n",
      "        [[0.4775, 0.5449],\n",
      "         [0.5225, 0.4551]],\n",
      "\n",
      "        [[0.4646, 0.5370],\n",
      "         [0.5354, 0.4630]],\n",
      "\n",
      "        [[0.4759, 0.5477],\n",
      "         [0.5241, 0.4523]],\n",
      "\n",
      "        [[0.4917, 0.5458],\n",
      "         [0.5083, 0.4542]],\n",
      "\n",
      "        [[0.4747, 0.5399],\n",
      "         [0.5253, 0.4601]],\n",
      "\n",
      "        [[0.4897, 0.5451],\n",
      "         [0.5103, 0.4549]]], grad_fn=<SoftmaxBackward0>)\n",
      "targets :  [tensor([0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with tqdm(desc='Testing', total=len(val_dl)) as pbar:\n",
    "    model.eval()\n",
    "    for i, (data, targets, path) in enumerate(val_dl):\n",
    "        pbar.update()\n",
    "        model.zero_grad()\n",
    "        out = model(data)\n",
    "        print(\"out : \",out)\n",
    "        t=out\n",
    "        print(\"out.data.cpu : \",out.data.cpu().numpy().argmax(axis=1))\n",
    "        s = F.softmax(out, 1)\n",
    "        print(\"softmax :\", s)\n",
    "        print(\"targets : \", targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62a3b649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([46, 2, 2])\n",
      "[[0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "print(t.shape)\n",
    "print(t.data.numpy().argmax(axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
